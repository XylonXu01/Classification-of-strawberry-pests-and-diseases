{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GPU显存\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "# tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "# #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "import os\n",
    "original_dataset_dir=\"/home/featurize/data/train_val/\"\n",
    "train_dir=os.path.join(original_dataset_dir,'train')\n",
    "validation_dir=os.path.join(original_dataset_dir,'val')\n",
    "#test_dir=os.path.join(original_dataset_dir,'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this in practice by using the convolutional base of the VGG16 network, trained on ImageNet, to extract interesting features from \n",
    "our cat and dog images, and then training a cat vs. dog classifier on top of these features.\n",
    "\n",
    "The VGG16 model, among others, comes pre-packaged with Keras. You can import it from the `keras.applications` module. Here's the list of \n",
    "image classification models (all pre-trained on the ImageNet dataset) that are available as part of `keras.applications`:\n",
    "\n",
    "* Xception\n",
    "* InceptionV3\n",
    "* ResNet50\n",
    "* VGG16\n",
    "* VGG19\n",
    "* MobileNet\n",
    "\n",
    "Let's instantiate the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 10:55:27.577671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:27.586258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:27.586566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:27.588023: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-19 10:55:27.588725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:27.589031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:27.589207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:28.447324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:28.447627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:28.447846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 10:55:28.448042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "conv_base = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    conv_base,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(256,kernel_regularizer=regularizers.l2(0.1),activation = 'relu'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    #tf.keras.layers.Dense(256,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(13,activation = 'softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our model looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 13)                3341      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,450,509\n",
      "Trainable params: 26,450,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 36\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 36\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base.trainable = True\n",
    "\n",
    "# set_trainable = False\n",
    "# for layer in conv_base.layers:\n",
    "#     if layer.name == 'block5_conv1':\n",
    "#         set_trainable = True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 987 images belonging to 13 classes.\n",
      "Found 252 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,)\n",
    "#       rotation_range=90,#图片翻转角度\n",
    "#       width_shift_range=0.2,#图片随机水平偏移的幅度\n",
    "#       height_shift_range=0.2,#图片随机垂直偏移的幅度\n",
    "#       shear_range=0.2,#剪切强度\n",
    "#       zoom_range=0.2,#随机放大\n",
    "#       horizontal_flip=True,\n",
    "#       fill_mode='nearest')\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,#有可能batch_size过大\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',#binary_crossentropy',#categorical_crossentropy\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     keras.callbacks.TensorBoard(\n",
    "#     log_dir='car_part_recognition',\n",
    "#     histogram_freq=1,\n",
    "#     embeddings_freq=1)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Strawberry___Leaf_scorch': 0,\n",
       " 'Strawberry___healthy': 1,\n",
       " '冻害': 2,\n",
       " '叶斑病': 3,\n",
       " '斜纹夜蛾': 4,\n",
       " '根腐病': 5,\n",
       " '灰霉病': 6,\n",
       " '病毒病': 7,\n",
       " '白粉虱': 8,\n",
       " '着色不良': 9,\n",
       " '缺素症': 10,\n",
       " '革腐病': 11,\n",
       " '黄萎病': 12}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices# 输出输入哪一类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 10:55:34.266193: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n",
      "2022-04-19 10:55:38.077892: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 32s 761ms/step - loss: 51.5463 - acc: 0.2320 - val_loss: 49.8360 - val_acc: 0.4643\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 19s 601ms/step - loss: 48.7618 - acc: 0.4873 - val_loss: 47.6507 - val_acc: 0.5357\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 19s 611ms/step - loss: 46.7331 - acc: 0.6130 - val_loss: 45.9407 - val_acc: 0.5992\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 19s 622ms/step - loss: 45.0168 - acc: 0.6879 - val_loss: 44.4275 - val_acc: 0.6270\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 19s 609ms/step - loss: 43.4108 - acc: 0.7639 - val_loss: 42.9785 - val_acc: 0.6825\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 20s 650ms/step - loss: 41.8633 - acc: 0.8186 - val_loss: 41.6645 - val_acc: 0.6865\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 19s 608ms/step - loss: 40.4417 - acc: 0.8693 - val_loss: 40.4966 - val_acc: 0.6548\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 18s 594ms/step - loss: 39.0415 - acc: 0.8987 - val_loss: 39.0014 - val_acc: 0.6905\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 18s 591ms/step - loss: 37.7316 - acc: 0.9189 - val_loss: 37.7986 - val_acc: 0.7063\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 19s 615ms/step - loss: 36.3568 - acc: 0.9554 - val_loss: 36.6091 - val_acc: 0.6905\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 35.0327 - acc: 0.9645 - val_loss: 35.2191 - val_acc: 0.7183\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 33.7288 - acc: 0.9585 - val_loss: 33.9178 - val_acc: 0.7183\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 19s 607ms/step - loss: 32.4343 - acc: 0.9676 - val_loss: 32.7231 - val_acc: 0.6944\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 18s 593ms/step - loss: 31.1150 - acc: 0.9807 - val_loss: 31.4562 - val_acc: 0.7421\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 19s 613ms/step - loss: 29.8224 - acc: 0.9828 - val_loss: 30.3016 - val_acc: 0.7063\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 28.5131 - acc: 0.9868 - val_loss: 29.1302 - val_acc: 0.7341\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 19s 606ms/step - loss: 27.2883 - acc: 0.9828 - val_loss: 27.7027 - val_acc: 0.7302\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 19s 614ms/step - loss: 26.0811 - acc: 0.9858 - val_loss: 26.7133 - val_acc: 0.7143\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 19s 606ms/step - loss: 24.9587 - acc: 0.9777 - val_loss: 25.4864 - val_acc: 0.7143\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 19s 621ms/step - loss: 23.8978 - acc: 0.9828 - val_loss: 24.2940 - val_acc: 0.7381\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 19s 618ms/step - loss: 22.8108 - acc: 0.9899 - val_loss: 23.3147 - val_acc: 0.7341\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 21.6921 - acc: 0.9889 - val_loss: 22.1801 - val_acc: 0.7183\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 18s 598ms/step - loss: 20.5737 - acc: 0.9980 - val_loss: 22.0183 - val_acc: 0.6270\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 19.4993 - acc: 0.9838 - val_loss: 20.0089 - val_acc: 0.7381\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 19s 606ms/step - loss: 18.5430 - acc: 0.9959 - val_loss: 19.2325 - val_acc: 0.7460\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 19s 616ms/step - loss: 17.5816 - acc: 0.9899 - val_loss: 18.2236 - val_acc: 0.7460\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 19s 593ms/step - loss: 16.6677 - acc: 0.9929 - val_loss: 17.2836 - val_acc: 0.7619\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 19s 601ms/step - loss: 15.7310 - acc: 0.9939 - val_loss: 16.4121 - val_acc: 0.7421\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 19s 612ms/step - loss: 14.8067 - acc: 0.9909 - val_loss: 15.4868 - val_acc: 0.7421\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 19s 611ms/step - loss: 13.9425 - acc: 0.9929 - val_loss: 14.5940 - val_acc: 0.7222\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 19s 617ms/step - loss: 13.1742 - acc: 0.9959 - val_loss: 14.1708 - val_acc: 0.7183\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 19s 612ms/step - loss: 12.3806 - acc: 0.9980 - val_loss: 13.2868 - val_acc: 0.7421\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 19s 618ms/step - loss: 8.9760 - acc: 0.9909 - val_loss: 10.0080 - val_acc: 0.7302\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 20s 630ms/step - loss: 8.4298 - acc: 0.9949 - val_loss: 9.5863 - val_acc: 0.7421\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 7.9855 - acc: 0.9939 - val_loss: 8.8705 - val_acc: 0.7579\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 19s 629ms/step - loss: 7.5319 - acc: 0.9980 - val_loss: 8.5367 - val_acc: 0.7460\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 19s 612ms/step - loss: 6.9895 - acc: 0.9990 - val_loss: 8.0535 - val_acc: 0.7341\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 19s 614ms/step - loss: 6.4923 - acc: 0.9949 - val_loss: 7.4526 - val_acc: 0.7500\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 19s 627ms/step - loss: 6.0619 - acc: 0.9980 - val_loss: 7.3161 - val_acc: 0.7381\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 18s 594ms/step - loss: 5.6527 - acc: 0.9949 - val_loss: 6.5529 - val_acc: 0.7421\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 19s 619ms/step - loss: 5.3403 - acc: 0.9959 - val_loss: 6.3846 - val_acc: 0.7302\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 19s 613ms/step - loss: 5.0344 - acc: 0.9919 - val_loss: 5.8328 - val_acc: 0.7579\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 19s 611ms/step - loss: 4.7444 - acc: 0.9990 - val_loss: 5.6939 - val_acc: 0.7421\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 18s 592ms/step - loss: 4.4278 - acc: 0.9990 - val_loss: 6.6652 - val_acc: 0.6429\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 19s 614ms/step - loss: 4.1562 - acc: 0.9889 - val_loss: 5.1466 - val_acc: 0.7421\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 19s 596ms/step - loss: 3.9319 - acc: 0.9990 - val_loss: 4.8831 - val_acc: 0.7937\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      verbose=1)\n",
    "      #callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.546280</td>\n",
       "      <td>0.232016</td>\n",
       "      <td>49.836044</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.761848</td>\n",
       "      <td>0.487335</td>\n",
       "      <td>47.650661</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.733074</td>\n",
       "      <td>0.612969</td>\n",
       "      <td>45.940712</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.016758</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>44.427456</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.410816</td>\n",
       "      <td>0.763931</td>\n",
       "      <td>42.978451</td>\n",
       "      <td>0.682540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.863255</td>\n",
       "      <td>0.818642</td>\n",
       "      <td>41.664474</td>\n",
       "      <td>0.686508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.441685</td>\n",
       "      <td>0.869301</td>\n",
       "      <td>40.496597</td>\n",
       "      <td>0.654762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.041504</td>\n",
       "      <td>0.898683</td>\n",
       "      <td>39.001434</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.731632</td>\n",
       "      <td>0.918946</td>\n",
       "      <td>37.798565</td>\n",
       "      <td>0.706349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.356770</td>\n",
       "      <td>0.955420</td>\n",
       "      <td>36.609138</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.032711</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>35.219074</td>\n",
       "      <td>0.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.728752</td>\n",
       "      <td>0.958460</td>\n",
       "      <td>33.917820</td>\n",
       "      <td>0.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32.434311</td>\n",
       "      <td>0.967579</td>\n",
       "      <td>32.723080</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31.114975</td>\n",
       "      <td>0.980750</td>\n",
       "      <td>31.456224</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29.822369</td>\n",
       "      <td>0.982776</td>\n",
       "      <td>30.301622</td>\n",
       "      <td>0.706349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.513086</td>\n",
       "      <td>0.986829</td>\n",
       "      <td>29.130180</td>\n",
       "      <td>0.734127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.288282</td>\n",
       "      <td>0.982776</td>\n",
       "      <td>27.702719</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.081079</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>26.713337</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.958735</td>\n",
       "      <td>0.977710</td>\n",
       "      <td>25.486361</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23.897823</td>\n",
       "      <td>0.982776</td>\n",
       "      <td>24.294016</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22.810778</td>\n",
       "      <td>0.989868</td>\n",
       "      <td>23.314703</td>\n",
       "      <td>0.734127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.692051</td>\n",
       "      <td>0.988855</td>\n",
       "      <td>22.180103</td>\n",
       "      <td>0.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.573730</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>22.018320</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19.499271</td>\n",
       "      <td>0.983789</td>\n",
       "      <td>20.008921</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.542963</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>19.232479</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.581644</td>\n",
       "      <td>0.989868</td>\n",
       "      <td>18.223644</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.667654</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>17.283625</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15.731039</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>16.412081</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.806746</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>15.486789</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.942547</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>14.594049</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.174217</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>14.170847</td>\n",
       "      <td>0.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.380570</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>13.286849</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11.576791</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>12.389605</td>\n",
       "      <td>0.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.857916</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>11.692561</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.108318</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>10.978799</td>\n",
       "      <td>0.718254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.529341</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>10.388888</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.975978</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>10.007970</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.429761</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>9.586326</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.985531</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>8.870507</td>\n",
       "      <td>0.757937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.531913</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>8.536738</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.989486</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>8.053506</td>\n",
       "      <td>0.734127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.492338</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>7.452624</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6.061877</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>7.316065</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.652727</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>6.552925</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.340328</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>6.384606</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.034441</td>\n",
       "      <td>0.991895</td>\n",
       "      <td>5.832777</td>\n",
       "      <td>0.757937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.744358</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>5.693859</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.427841</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>6.665163</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.156162</td>\n",
       "      <td>0.988855</td>\n",
       "      <td>5.146571</td>\n",
       "      <td>0.742063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.931877</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>4.883101</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc   val_loss   val_acc\n",
       "0   51.546280  0.232016  49.836044  0.464286\n",
       "1   48.761848  0.487335  47.650661  0.535714\n",
       "2   46.733074  0.612969  45.940712  0.599206\n",
       "3   45.016758  0.687943  44.427456  0.626984\n",
       "4   43.410816  0.763931  42.978451  0.682540\n",
       "5   41.863255  0.818642  41.664474  0.686508\n",
       "6   40.441685  0.869301  40.496597  0.654762\n",
       "7   39.041504  0.898683  39.001434  0.690476\n",
       "8   37.731632  0.918946  37.798565  0.706349\n",
       "9   36.356770  0.955420  36.609138  0.690476\n",
       "10  35.032711  0.964539  35.219074  0.718254\n",
       "11  33.728752  0.958460  33.917820  0.718254\n",
       "12  32.434311  0.967579  32.723080  0.694444\n",
       "13  31.114975  0.980750  31.456224  0.742063\n",
       "14  29.822369  0.982776  30.301622  0.706349\n",
       "15  28.513086  0.986829  29.130180  0.734127\n",
       "16  27.288282  0.982776  27.702719  0.730159\n",
       "17  26.081079  0.985816  26.713337  0.714286\n",
       "18  24.958735  0.977710  25.486361  0.714286\n",
       "19  23.897823  0.982776  24.294016  0.738095\n",
       "20  22.810778  0.989868  23.314703  0.734127\n",
       "21  21.692051  0.988855  22.180103  0.718254\n",
       "22  20.573730  0.997974  22.018320  0.626984\n",
       "23  19.499271  0.983789  20.008921  0.738095\n",
       "24  18.542963  0.995947  19.232479  0.746032\n",
       "25  17.581644  0.989868  18.223644  0.746032\n",
       "26  16.667654  0.992908  17.283625  0.761905\n",
       "27  15.731039  0.993921  16.412081  0.742063\n",
       "28  14.806746  0.990881  15.486789  0.742063\n",
       "29  13.942547  0.992908  14.594049  0.722222\n",
       "30  13.174217  0.995947  14.170847  0.718254\n",
       "31  12.380570  0.997974  13.286849  0.742063\n",
       "32  11.576791  0.994934  12.389605  0.726190\n",
       "33  10.857916  0.997974  11.692561  0.730159\n",
       "34  10.108318  0.993921  10.978799  0.718254\n",
       "35   9.529341  0.994934  10.388888  0.738095\n",
       "36   8.975978  0.990881  10.007970  0.730159\n",
       "37   8.429761  0.994934   9.586326  0.742063\n",
       "38   7.985531  0.993921   8.870507  0.757937\n",
       "39   7.531913  0.997974   8.536738  0.746032\n",
       "40   6.989486  0.998987   8.053506  0.734127\n",
       "41   6.492338  0.994934   7.452624  0.750000\n",
       "42   6.061877  0.997974   7.316065  0.738095\n",
       "43   5.652727  0.994934   6.552925  0.742063\n",
       "44   5.340328  0.995947   6.384606  0.730159\n",
       "45   5.034441  0.991895   5.832777  0.757937\n",
       "46   4.744358  0.998987   5.693859  0.742063\n",
       "47   4.427841  0.998987   6.665163  0.642857\n",
       "48   4.156162  0.988855   5.146571  0.742063\n",
       "49   3.931877  0.998987   4.883101  0.793651"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./实验记录/VGG19迁移学习.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('草莓VGG19（224）.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our results again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('car_part_ABCD(裁剪后).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
